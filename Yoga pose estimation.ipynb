{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing mediapipe pose class\n",
    "mp_pose=mp.solutions.pose\n",
    "\n",
    "#setting the pose function\n",
    "pose=mp_pose.Pose(static_image_mode=True,min_detection_confidence=0.3,model_complexity=2)\n",
    "\n",
    "#initialising mediapipe drawing class,useful for annotation\n",
    "mp_drawing=mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image,pose,display=True):\n",
    "    output_image=image.copy()\n",
    "    imageRGB=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    results=pose.process(imageRGB)\n",
    "    height,width,_=image.shape\n",
    "    landmarks=[]\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image=output_image,landmark_list=results.pose_landmarks,\n",
    "                                 connections=mp_pose.POSE_CONNECTIONS)\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.append((int(landmark.x*width),int(landmark.y*height),(landmark.z*width)))\n",
    "    if display:\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "    else:\n",
    "        return output_image,landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1,landmark2,landmark3):\n",
    "    #get the required landmarks coordinates\n",
    "    x1,y1,_=landmark1\n",
    "    x2,y2,_=landmark2\n",
    "    x3,y3,_=landmark3\n",
    "    \n",
    "    #calculate the angle between the three points\n",
    "    angle=math.degrees(math.atan2(y3-y2,x3-x2)-math.atan2(y1-y2,x1-x2))\n",
    "    \n",
    "    #check if angle is less than 0\n",
    "    if angle<0:\n",
    "        angle+=360\n",
    "    return angle\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPose(landmarks,output_image,display=False):\n",
    "    label='Unknown Pose'\n",
    "    color=(0,0,255)\n",
    "    #calculate the required angles\n",
    "    left_elbow_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "    right_elbow_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "    \n",
    "    left_shoulder_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "    \n",
    "    right_shoulder_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    \n",
    "    left_knee_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    \n",
    "    right_knee_angle=calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    \n",
    "    #Check if it is warrior II pose or the T pose-\n",
    "    if left_elbow_angle>165 and left_elbow_angle<195 and right_elbow_angle>165 and right_elbow_angle<195:\n",
    "        if left_shoulder_angle>80 and left_shoulder_angle<110 and right_shoulder_angle>80 and right_shoulder_angle<110:\n",
    "            if left_knee_angle>165 and left_knee_angle<195 or right_knee_angle>165 and right_knee_angle<195:\n",
    "                     if left_knee_angle>90 and left_knee_angle<120 or right_knee_angle>90 and right_knee_angle<120:\n",
    "                        label=\"Warrior II Pose\"\n",
    "            \n",
    "            if left_knee_angle>160 and left_knee_angle<195 and right_knee_angle>160 and right_knee_angle<195:\n",
    "                label='T Pose'\n",
    "                \n",
    "    #Tree pose\n",
    "    if left_knee_angle>165 and left_knee_angle<195 or right_knee_angle>165 and right_knee_angle<195:\n",
    "        if left_knee_angle>315 and left_knee_angle<335 or right_knee_angle>25 and right_knee_angle<45:\n",
    "            label='Tree Pose'\n",
    "\n",
    "\n",
    "   \n",
    "    if label!='Unknown Pose':\n",
    "        color=(0,255,0)\n",
    "        \n",
    "    cv2.putText(output_image,label,(10,30),cv2.FONT_HERSHEY_PLAIN,2,color,2)\n",
    "    \n",
    "    if display:\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::,-1]);plt.title(\"Output image\");plt.axis('off');\n",
    "    else:\n",
    "        return output_image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Classification on Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set pose functon for video\n",
    "pose_video=mp_pose.Pose(static_image_mode=False,min_detection_confidence=0.5,model_complexity=1)\n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('Pose Classification',cv2.WINDOW_NORMAL)\n",
    "# video.set(3,1280)\n",
    "# video.set(4,960)\n",
    "time1=0\n",
    "while video.isOpened():\n",
    "    ok,frame=video.read()\n",
    "    \n",
    "    if not ok:\n",
    "        break\n",
    "    frame=cv2.flip(frame,1)\n",
    "    frame_height,frame_width,_=frame.shape\n",
    "   # frame=cv2.resize(frame,(int(frame_width*(640/frame_height)),640))\n",
    "    frame,_=detectPose(frame,pose_video,display=False)\n",
    "    \n",
    "    time2=time()\n",
    "    if (time2-time1)>0:\n",
    "        frames_per_second=1.0/(time2-time1)\n",
    "        cv2.putText(frame,'FPS:{}'.format(int(frames_per_second)),(10,30),cv2.FONT_HERSHEY_PLAIN,2,(0,255,0),3)\n",
    "    time1=time2\n",
    "    cv2.imshow('Pose Classification',frame)\n",
    "    k=cv2.waitKey(1)& 0xFF\n",
    "    if(k==27):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set pose functon for video\n",
    "pose_video=mp_pose.Pose(static_image_mode=False,min_detection_confidence=0.5,model_complexity=1)\n",
    "\n",
    "camera_video=cv2.VideoCapture(0)\n",
    "# camera_video.set(3,1280)\n",
    "# camera_video.set(4,960)\n",
    "cv2.namedWindow('Pose Classification',cv2.WINDOW_NORMAL)\n",
    "\n",
    "while camera_video.isOpened():\n",
    "    ok,frame=camera_video.read()\n",
    "    \n",
    "    if not ok:\n",
    "        break\n",
    "    frame=cv2.flip(frame,1)\n",
    "    frame_height,frame_width,_=frame.shape\n",
    "    #frame=cv2.resize(frame,(int(frame_width*(640/frame_height)),640))\n",
    "    frame,landmarks=detectPose(frame,pose_video,display=False)\n",
    "    if landmarks:\n",
    "        frame,_=classifyPose(landmarks,frame,display=False)\n",
    "    cv2.imshow('Pose Classification',frame)\n",
    "    k=cv2.waitKey(1)& 0xFF\n",
    "    if(k==27):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
